# ===========================================
# OpenAI-Compatible Assistant Environment Variables
# ===========================================
# Copy this file to .env and fill in your values
# For Cloudflare Workers, set secrets using: wrangler secret put <SECRET_NAME>

# ===========================================
# CRITICAL SECRETS (Set via wrangler secret put)
# ===========================================

# API Keys for LLM Providers
GEMINI_API_KEY=your_gemini_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
API_KEY=your_application_api_key_here

# Security Keys
RATE_LIMIT_BYPASS_KEY=your_rate_limit_bypass_key_here
GC_ADMIN_KEY=your_gc_admin_key_here

# ===========================================
# CLOUD FLARE WORKER BINDINGS
# ===========================================

# R2 Storage Buckets (Configured in wrangler.toml)
# These are automatically bound by Cloudflare Workers runtime
# R2_BUCKET=main_storage_bucket
# ASSISTANT_R2=assistant_specific_storage

# ===========================================
# APPLICATION CONFIGURATION
# ===========================================

# Environment
NODE_ENV=development

# Logging Configuration
LOG_LEVEL=info
LOG_REQUESTS=true
LOG_ERRORS=true

# ===========================================
# SECURITY CONFIGURATION
# ===========================================

# Authentication
ENABLE_AUTH=true

# Security Headers
ENABLE_SECURITY_HEADERS=true
CONTENT_SECURITY_POLICY=default-src 'self'; script-src 'self' 'unsafe-inline'
STRICT_TRANSPORT_SECURITY=max-age=31536000; includeSubDomains

# Error Handling
ENABLE_ERROR_TRACKING=true
ENABLE_METRICS=true
EXPOSE_ERROR_DETAILS=false
ERROR_TRACKING_URL=https://your-error-tracking-service.com

# ===========================================
# CORS CONFIGURATION
# ===========================================

CORS_ORIGINS=*
ENABLE_CORS=true

# ===========================================
# REQUEST CONFIGURATION
# ===========================================

# Request Limits
MAX_REQUEST_SIZE=10485760
REQUEST_TIMEOUT=30000

# Request Logging
ENABLE_REQUEST_LOGGING=true

# ===========================================
# RATE LIMITING CONFIGURATION
# ===========================================

ENABLE_RATE_LIMIT=true
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW_MS=60000

# ===========================================
# FILE UPLOAD CONFIGURATION
# ===========================================

MAX_FILE_SIZE=26214400
ALLOWED_FILE_TYPES=image/*,text/*,application/pdf,application/json

# ===========================================
# PROVIDER CONFIGURATION
# ===========================================

# OpenAI Provider
PROVIDER_OPENAI_ENABLED=false
PROVIDER_OPENAI_BASE_URL=https://api.openai.com/v1

# Gemini Provider
PROVIDER_GEMINI_ENABLED=false
PROVIDER_GEMINI_BASE_URL=https://generativelanguage.googleapis.com

# Common Provider Settings
PROVIDER_TIMEOUT=30000
PROVIDER_MAX_RETRIES=3

# Fallback Configuration
PROVIDER_FALLBACK_ENABLED=true
PROVIDER_FALLBACK_MAX_RETRIES=3
PROVIDER_FALLBACK_RETRY_DELAY=1000

# ===========================================
# SETUP INSTRUCTIONS
# ===========================================

# 1. Set secrets using wrangler:
#    wrangler secret put GEMINI_API_KEY
#    wrangler secret put API_KEY
#    wrangler secret put RATE_LIMIT_BYPASS_KEY
#    wrangler secret put GC_ADMIN_KEY
#    wrangler secret put OPENAI_API_KEY (optional)

# 2. Configure R2 buckets in wrangler.toml:
#    [[r2_buckets]]
#    binding = "R2_BUCKET"
#    bucket_name = "openai-compatible-assistant"
#
#    [[r2_buckets]]
#    binding = "ASSISTANT_R2"
#    bucket_name = "assistant-data"

# 3. Deploy the worker:
#    wrangler deploy

# 4. Set environment variables for different environments:
#    wrangler secret put <SECRET_NAME> --env production

# 5. To enable providers, set the API keys and then update the ENABLED flags:
#    PROVIDER_GEMINI_ENABLED=true (if GEMINI_API_KEY is set)
#    PROVIDER_OPENAI_ENABLED=true (if OPENAI_API_KEY is set)

# ===========================================
# VARIABLE REFERENCE
# ===========================================

# Required Variables (must be set):
# - GEMINI_API_KEY: Required for Gemini provider functionality
# - API_KEY: Main application API key for authentication
# - R2_BUCKET: Main storage bucket (Cloudflare binding)

# Optional Variables (have defaults):
# - OPENAI_API_KEY: Only required if using OpenAI provider
# - NODE_ENV: Defaults to 'development'
# - LOG_LEVEL: Defaults to 'info' (debug, info, warn, error)
# - CORS_ORIGINS: Defaults to '*' (use comma-separated for multiple)
# - MAX_REQUEST_SIZE: Defaults to 10MB
# - REQUEST_TIMEOUT: Defaults to 30 seconds
# - RATE_LIMIT_REQUESTS: Defaults to 100 requests per window
# - RATE_LIMIT_WINDOW_MS: Defaults to 60000ms (1 minute)
# - MAX_FILE_SIZE: Defaults to 25MB
# - ALLOWED_FILE_TYPES: File types allowed for upload

# Feature Flags (enable/disable functionality):
# - ENABLE_AUTH: Enable API key authentication
# - ENABLE_RATE_LIMIT: Enable rate limiting
# - ENABLE_CORS: Enable CORS headers
# - ENABLE_REQUEST_LOGGING: Log incoming requests
# - ENABLE_ERROR_TRACKING: Enable error tracking
# - ENABLE_METRICS: Enable metrics collection
# - ENABLE_SECURITY_HEADERS: Add security headers
# - PROVIDER_*: Enable specific AI providers
# - PROVIDER_FALLBACK_*: Configure fallback behavior

# Security Considerations:
# - Never commit secrets to version control
# - Use wrangler secret put for sensitive values
# - Rotate API keys regularly
# - Use strong, unique values for bypass keys
# - Set appropriate CORS origins in production